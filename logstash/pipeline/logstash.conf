input {
  udp {
    port => "514"
    type => "syslog-cisco"
  }

#  tcp {
#    port => "5514"
#    type => "syslog-cisco"
#  }

}
#
# FILTER - Try to parse the cisco log format
#
# Configuration:
#   clock timezone ARIZONA -7
#   no clock summer-time
#   ! ntp is important as it could change syslog/grok pattern (*)
#   ntp server 0.0.0.0 prefer
#   ntp server 129.6.15.28
#   ntp server 131.107.13.100
#   service timestamps log datetime msec show-timezone
#   service timestamps debug datetime msec show-timezone
#   logging source-interface Loopback0
#   ! Two logging servers for redundancy
#   logging host 0.0.0.0 transport tcp port 8514
#   logging host 0.0.0.0 transport tcp port 8514
#   logging trap 6


filter {
  # NOTE: The frontend logstash servers set the type of incoming messages.
  if [type] == "syslog-cisco" {
    # The switches are sending the same message to all syslog servers for redundancy, this allows us to
    ## only store the message in elasticsearch once by generating a hash of the message and using that as
    ## the document_id.
    fingerprint {
      source              => [ "message" ]
      method              => "SHA1"
      key                 => "Some super secret passphrase for uniqueness."
      concatenate_sources => true
    }

    # Parse the log entry into sections.  Cisco doesn't use a consistent log format, unfortunately.
    grok {
      # There are a couple of custom patterns associated with this filter.
      patterns_dir => [ "/opt/logstash/patterns" ]

      match => [
        # IOS-XE Log Format
				# *Jan 18 05:39:54.124: %SYS-5-CONFIG_I: Configured from console by cisco on vty0 (10.24.27.143)
				"message", "%{NUMBER:pri}(%{NUMBER:log_sequence#})?:( %{NUMBER}:)? *%{DATA:log_date}: %%{DATA:facility}-%{INT:severity_level}-%{DATA:facility_mnemonic}: %{GREEDYDATA:message}",
				"message", "%{SYSLOG5424PRI}(%{NUMBER:log_sequence#})?:( %{NUMBER}:)? %{CISCOTIMESTAMPTZ:log_date}: %%{CISCO_REASON:facility}-%{INT:severity_level}-%{CISCO_REASON:facility_mnemonic}: %{GREEDYDATA:message}",
        "message", "%{SYSLOG5424PRI}(%{NUMBER:log_sequence#})?:( %{NUMBER}:)? %{CISCOTIMESTAMPTZ:log_date}: %%{CISCO_REASON:facility}-%{CISCO_REASON:facility_sub}-%{INT:severity_level}-%{CISCO_REASON:facility_mnemonic}: %{GREEDYDATA:message}",

        # Nexus Log Format
				# 2018 Jan 18 05:09:49.334 agg3 %VSHD-5-VSHD_SYSLOG_CONFIG_I: Configured from vty by cisco on 10.24.27.143@pts/6

        "message", "%{NUMBER:pri}(%{NUMBER:log_sequence#})?: %{NEXUSTIMESTAMP:log_date}: %%{CISCO_REASON:facility}-%{INT:severity_level}-%{CISCO_REASON:facility_mnemonic}: %{GREEDYDATA:message}",
        "message", "%{SYSLOG5424PRI}(%{NUMBER:log_sequence#})?: %{NEXUSTIMESTAMP:log_date}: %%{CISCO_REASON:facility}-%{CISCO_REASON:facility_sub}-%{INT:severity_level}-%{CISCO_REASON:facility_mnemonic}: %{GREEDYDATA:message}",

        # IOS-XR Log Format
        # RP/0/RP0/CPU0:Jan 18 16:31:05 UTC: config[67413]: %MGBL-SYS-5-CONFIG_I : Configured from console by cisco on vty0 (10.153.76.78)
        "message", "%{NUMBER:pri}(%{NUMBER:log_sequence#})?:( %{NUMBER}:)? *%{DATA:log_date}: %{DATA:log_id}: %%{DATA:facility}-%{INT:severity_level}-%{DATA:facility_mnemonic}: %{GREEDYDATA:message}"
	
	#FTD Log Format
	#Example TODO
	"message"=>"<%{POSINT:syslog_pri}>%{TIMESTAMP_ISO8601:timestamp}%{SPACE}\%FTD-%{DATA:severity}-%{DATA:eventid}: %{GREEDYDATA:msg}"
      ]

      overwrite => [ "message" ]

      add_tag => [ "cisco" ]

      remove_field => [ "syslog5424_pri", "@version" ]
    }
  }

  # If we made it here, the grok was sucessful
  if "cisco" in [tags] {
    date {
      match => [
        "log_date",

        # IOS
        "MMM dd HH:mm:ss.SSS ZZZ",
        "MMM dd HH:mm:ss ZZZ",
        "MMM dd HH:mm:ss.SSS",

        # Nexus
        "YYYY MMM dd HH:mm:ss.SSS ZZZ",
        "YYYY MMM dd HH:mm:ss ZZZ",
        "YYYY MMM dd HH:mm:ss.SSS",

        # Hail marry
        "ISO8601"
      ]
    }

    # Add the log level's name instead of just a number.
    mutate {
      gsub => [
        "severity_level", "0", "0 - Emergency",
        "severity_level", "1", "1 - Alert",
        "severity_level", "2", "2 - Critical",
        "severity_level", "3", "3 - Error",
        "severity_level", "4", "4 - Warning",
        "severity_level", "5", "5 - Notification",
        "severity_level", "6", "6 - Informational"
      ]
    }

    # Translate the short facility name into a full name.
    # NOTE:  This is a third party plugin: logstash-filter-translate
    translate {
      field       => "facility"
      destination => "facility_full"

      dictionary => [
        "AAA", "Authentication, authorization, and accounting",
        "BGP", "Border Gateway Protocol",
        "CPU_INTF_FPGA", "CPU Interface FPGA",
        "CPU_MONITOR", "CPU monitor",
        "CRYPTO", "Encryption",
        "CRYPTO_HA", "Crypto High Availability",
        "CRYPTO_HA_IKE", "Crypto High Availability",
        "CRYPTO_HA_IPSEC", "Crypto High Availability",
        "DOT1Q", "802.1q",
        "HSRP", "Hot Standby Router Protocol (HSRP)",
        "LINECARD", "Node Route Processor (NRP) line card",
        "LINEPROTO", "Line Protocol",
        "LINK", "Data link",
        "OSPF", "Open Shortest Path First (OSPF)",
        "SPAN", "Spanning Tree Protocol",
        "SPANTREE", "Spanning Tree",
        "SPANTREE_FAST", "Spanning Tree Fast Convergence",
        "SPANTREE_VLAN_SW", "Spanning Tree VLAN switch",
        "SYS", "Operating system"

      ]
    } # translate
  } # if
} # filter



output {

	## Useful for debugging
	#	stdout { codec => rubydebug }
	#	file {
	#		path => "/var/log/network.log"
	#	}

	elasticsearch {
		hosts => "elasticsearch:9200"
		index => "syslog"
	}
}
